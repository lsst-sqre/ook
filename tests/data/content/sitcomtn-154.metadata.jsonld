{
  "name": "Initial studies of photometric redshifts with LSSTComCam from DP1\n",
  "@context": [
    "https://raw.githubusercontent.com/codemeta/codemeta/2.0-rc/codemeta.jsonld",
    "http://schema.org"
  ],
  "@id": "https://sitcomtn-154.lsst.io",
  "@type": [
    "Report",
    "SoftwareSourceCode"
  ],
  "articleBody": "\\documentclass[SE,lsstdraft,authoryear,toc]{lsstdoc}\n\n\\newcommand{SITCOMTN}{SITCOMTN}\n\\newcommand{154}{154}\n\\newcommand{c59488d}{c59488d}\n\\newcommand{2025-07-09}{2025-07-09}\n\n\n\n\\usepackage{xcolor}\n\\usepackage{hyperref}\n\\usepackage{fancyvrb}\n\n\n\n\n\n\\newcommand{{\\color{#2}{{\\bf #1} #3}}}[3]{{\\color{#2}{{\\bf #1} #3}}}\n\n\\newcommand{\\PersonalTag{}{red}{#1}}[1]{{\\color{#2}{{\\bf #1} #3}}{}{red}{#1}}\n\\newcommand{\\PersonalTag{Eric}{purple}{#1}}[1]{{\\color{#2}{{\\bf #1} #3}}{Eric}{purple}{#1}}\n\\newcommand{{\\color{red} citation needed {#1}}\\xspace}[1]{{\\color{red} citation needed {#1}}\\xspace}\n\\newcommand{{\\color{gray} [code TODO: {#1}]}\\xspace}[1]{{\\color{gray} [code TODO: {#1}]}\\xspace}\n\\newcommand{\\textbf{\\color{blue} INSTRUCTIONS FOR CONTRIBUTORS ({#1}): {#2}}\\xspace}[2]{\\textbf{\\color{blue} INSTRUCTIONS FOR CONTRIBUTORS ({#1}): {#2}}\\xspace}\n\n\\newcommand{photo-$z$\\xspace}{photo-$z$\\xspace}\n\\newcommand{photo-$z$\\xspaces}{photo-$z$s\\xspace}\n\\newcommand{\\textbf{#1}}[1]{\\textbf{#1}}\n\\newcommand{\\textit{#1}}[1]{\\textit{#1}}\n\\newcommand{``#1''}[1]{``#1''}\n\n\n\n\n\n\n\\title{Initial studies of photometric redshifts with LSSTComCam from DP1}\n\n\n\n\\hypersetup{\n    pdftitle={Initial studies of photometric redshifts with LSSTComCam from DP1},\n    pdfauthor={Melissa Graham},\n    pdfkeywords={}\n}\n\n\n\n\n\\author{\n  Eric Charles,\n  John Franklin Crenshaw,\n  Tianqing Zhang,\n  Sam Schmidt,\n  Prakruth Adari,\n  Johann Cohen-Tanugi,\n  Melissa Graham,\n  Julia Gschwend,\n  Bryce Kalmbach,\n  Arun Kannawadi,\n  Alex Malz,\n  Sidney Mau,\n  Ignacio Sevilla-Noarbe,\n  Rance Solomon,\n  Dan Taranu\n}\n\n\\setDocRef{SITCOMTN-154}\n\\setDocUpstreamLocation{\\url{https://github.com/lsst-sitcom/sitcomtn-154}}\n\n\\date{2025-07-09}\n\n\n\n\n\\setDocAbstract{\nThis technote holds reports based on the first analyses of the Data\nPreview 1 (DP1) data by the Science Unit for photometric\nredshifts.  Although photometric redshifts are not a official DP1 data\nproduct, the ``Photo-z Science Unit'' generated photo-$z$\\xspace\nestimates for every galaxy in DP1 using the available multi-band\nimaging on a best-effort basis.   This work included developing\ntraining and test datasets by matching DP1 data to high-quality\nreference redshifts obtained with spectroscopy, Grism data, and multi-band photometry.\nThe Science Unit used the RAIL software package to make\nphotometric redshift estimates using eight different algorithms,\ndeveloped simple scientific performance metrics, used those metrics to\nexplore how the performance of the algorithms varied with\nconfiguration changes, derived more optimized configurations of the\nalgorithms and tested the performance of those configurations.\nThis work, the resulting data products and expected data distribution\nmechanism are all described there.\n}\n\n\n\n\n\n\\setDocChangeRecord{\n  \\addtohist{1}{2025-06-30}{Initial release, coincident with release of DP1}{Melissa Graham}\n}\n\n\n\\begin{document}\n\n\n\\maketitle\n\n\n\n\n\n\n\\section{Introduction}\n\\label{sec:intro:0}\n\nThe Vera C. Rubin Observatory\u00e2\u20ac\u2122s Data Preview 1 (DP1) marks an important milestone in preparing for the forthcoming Legacy Survey of Space and Time (LSST), offering a valuable opportunity to test and validate scientific tools and workflows on precursor imaging data~\\citep{RTN-095}. Among the core scientific objectives of LSST is the estimation of photometric redshifts (photo-$z$\\xspaces) for billions of galaxies, enabling extragalactic astrophysics and cosmological analyses that rely on redshift estimates and distributions.  Accordingly, the Rubin project developed a roadmap to providing high-quality photo-$z$\\xspaces for the scientific community~\\citep{DMTN-049}.\n\nAlthough photo-$z$\\xspace are not a DP1 deliverable, the ``Photo-z Science Unit'' was asked to generate photo-$z$\\xspace estimates for every galaxy in DP1 using the available multi-band imaging on a best-effort basis, laying the groundwork for future large-scale applications.  This effort required integrating realistic data processing with scalable machine learning techniques capable of delivering precise redshift predictions across varied galaxy populations.\n\nTo accomplish this task, we employed the RAIL (Redshift Assessment Infrastructure Layers) software package, a flexible and modular platform designed for photo-$z$\\xspace estimation and evaluation\\citep{RAIL}.  Specifically, we used RAIL to train photo-$z$\\xspace estimation algorithms on high-quality redshift training sets cross-matched to the DP1 photometric catalog.\n\nThis note describes the resulting best-effort photo-$z$\\xspace catalogs, which should be regarded as extremely preliminary, and the tools used and the steps taken to generate those catalogs.  In addition, we describe relevant features of the DP1 photometric data, the spectroscopic calibration datasets and the resulting photo-$z$\\xspace catalogs.   Additional details about data products and data distribution are included as appendices.\n\nWe expect feedback from science users as they explore the data and discover issues that we have not anticipated, and that we will incorporate that feedback in future work.\n\n\\section{Data}\n\\label{sec:data:0}\n\n\\subsection{Rubin DP1}\n\\label{sec:data:dp1}\n\nThe Rubin Observatory\u00e2\u20ac\u2122s Data Preview 1 (DP1) dataset is the first public release of Rubin observatory imaging data processed through the LSST Science Pipelines \\citep{PSTN-019}, serving as a critical testbed for scientific and technical validation ahead of full LSST operations.  DP1 is based on observations from the LSST commissioning camera (LSSTComCam) and includes multi-band optical imaging in u, g, r, i, z and y filters over several square degrees of sky.  The dataset consists of processed images, source catalogs, and associated metadata, all formatted using the Rubin Data Butler system \\citep{2022SPIE12189E..11J} in the same way as full LSST data products.  Although smaller in scale than future LSST datasets, DP1 offers realistic photometric measurements, object detection, and data structures, making it an invaluable resource for developing and testing algorithms for tasks such as photo-$z$\\xspace estimation, object classification, and data quality assessment.\n\nCritially, the fields selected for ComCam observation included the Extended Chandra Deep Field South (ECDFS), for which many high-quailty redshifts exist from other surveys.\n\n\n\\subsubsection{Preparation of photometric object catalogs}\n\\label{sec:data:dp1:preparation}\n\nThe Rubin Data Management (Rubin DM) pipeline measures multiple types of object photometry, the first stage in creating a photo-$z$\\xspace catalog was to determine which measured photometry we would use as inputs.  In this note, we generally use the 1.0 arc-second Gaussian Aperture fluxes and their associated errors, e.~g.~\\texttt{u\\_gaap1p0Flux} and \\texttt{u\\_gaap1p0FluxErr}.  These fluxes should provide good measures of consistent galaxy colors within the defined aperture, ideal for photo-$z$\\xspace estimation, though they may not necessarily reflect the colors of the overall galaxy if there is a significant color gradient and the galaxy is larger than the 1.0 arc-second aperture.  This choice of photometric measurement may not be ideal, and investigation into the optimized set of photometric inputs will continue into the future.   The only exceptions to this are that we used \\texttt{i\\_psfFlux} in the initial broad data cuts, and that we briefly explored several of the other fluxes as part of the initial validation of our photo-$z$\\xspace analysis pipelines.\n\nPreparing object catalog \\citep{10.71929/rubin/2570325} data for photo-$z$\\xspace algorithm training and estimation included five steps:\n\n\\begin{enumerate}\n\\item{Applying quality cuts to the object catalog.   We developed selections for the training and test datasets (\\textit{#1}{match\\_xxx}), and two additional selections for full DP1 catalogs: one applicable for fields with observations in only four bands (\\textit{#1}{gold\\_4\\_band}), the other for fields with observations in all six bands (\\textit{#1}{gold}).  These selections are described below.}\n\\item{Converting fluxes in nJy to AB magnitudes ($m_\\text{AB} = -2.5 \\log_{10}(f_\\nu / \\text{nJy}) + 31.4$)}\n\\item{De-reddening to account for Galactic dust.  We use the SFD dust maps\\citep{SFD}.}\n\\item{Cross-matching objects with reference catalogs that include redshift information as described in Sec.~\\ref{sec:data:reference}.}\n\\item{Shuffling and splitting the resulting catalog into ``#1''{training} and ``#1''{test} data sets.}\n\\end{enumerate}\n\nThe data selection criteria that we used were:\n\\begin{itemize}\n\\item{\\textit{#1}{match\\_prelim}: first version of matching to high-quality redshift catalogs in the ECDFS field,  see Sec.~\\ref{sec:data:reference}.}\n\\item{\\textit{#1}{match\\_ecdfs}: updated matching to high-quality redshift datalogs in the ECDFS field, see Sec.~\\ref{sec:data:reference}.}\n\\item{\\textit{#1}{match\\_desi}: matching to DESI redshift catalogs in the \\textbf{#1}{Rubin SV 38 7} field, see Sec.~\\ref{sec:data:desi}.}\n\\item{\\textit{#1}{gold}: \\code{Detection in 'ugrizy'  \\&\\& i\\_psfFlux / i\\_psfFluxErr > 5 \\&\\& ( g\\_extendedness > 0.5 || r\\_extendedness > 0.5)}.}\n\\item{\\textit{#1}{gold\\_4\\_band}: \\code{Detection in 'griz' \\&\\& i\\_psfFlux / i\\_psfFluxErr > 5 \\&\\& ( g\\_extendedness > 0.5 || r\\_extendedness > 0.5)}.}\n\\end{itemize}\n\nTo create the ``#1''{training} and ``#1''{test} data sets, we followed steps 1--5, while for the larger unlabeled data sets we followed steps 1--3.  Specifically, for DP1, the \\textbf{#1}{ECDFS}, ``#1''{EDFS} and ``#1''{Rubin SV 95 -25} fields have observation in 6 bands, and we applied the \\textit{#1}{gold} target selection.   In \\textbf{#1}{Rubin SV 38 7}, DP1 only has observation in 4 bands (``griz''), therefore we applied the \\textit{#1}{gold\\_4\\_band} target selection to that field.\n\n\nAll of these datasets are summarized in Tab.~\\ref{tab:dataset}.\n\n\\begin{table*}\n\\centering\n\\begin{tabular}{lll}\n \\hline\n    Data set & Selection & Number of objects\\\\\n \\hline\n \\hline\n  DP1 & None & 2,299,757 \\\\\n ECDFS+EDFS+SV\\_95 & \\textit{#1}{gold} & 375,610\\\\\n SV\\_38 & \\textit{#1}{gold\\_4\\_band} & 169,034\\\\\n training\\_v1 & \\textit{#1}{match\\_prelim}  & 7,000\\\\\n test\\_v1 & \\textit{#1}{match\\_prelim}  & 2,437 \\\\\n training\\_v2 & \\textit{#1}{match\\_ecdfs}  & 4,803\\\\\n test\\_v2 & \\textit{#1}{match\\_ecdfs}  & 1,201 \\\\\n test\\_DESI & \\textit{#1}{match\\_desi}  & 2,728 \\\\\n \\hline\n\\end{tabular}\n\\caption{ Summary of the datasets used in this work.  Note that to train models on four-band photometry, we used the same training and test sets as for six-band photometry, but configured the algorithms only to use the 'griz' bands.}\n\\label{tab:dataset}\n\\end{table*}\n\n\n\n\\subsubsection{Data properties}\n\\label{sec:data:dp1:properties}\n\nWe have developed tools to generate diagnostic plots of both the input object catalogs and the photo-$z$\\xspace estimates as part of our data analysis.\nFig.~\\ref{fig:dp_mags} shows histograms of the AB magnitudes in 1.0 arc-second apertures of objects in the ``#1''{test\\_v1} dataset, which includes an explicit magnitude cut, $m_{i} < 26.0$.\nFig.~\\ref{fig:dp_mag_i_v_redshift} shows the correlation between magnitude and redshift for all objects in the ``#1''{test\\_v1} data set.\nFig.~\\ref{fig:dp_color_v_redshift} shows the ``adjacent band colors'', i.e., $u-g$, $g-r$, $r-i$, $i-z$, $z-y$ versus redshift for the same, with a series of SED templates (as used by template-fitting algorithms, see Sec.~\\ref{sec:method:template}) overlaid.\nFinally, Fig.~\\ref{fig:dp_color_v_color} shows the color-color plots for the same adjacent colors.  In all cases, the 1.0 arc-second aperture magnitudes are used for plotting.\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/mags.pdf}\n    \\caption{1.0 arc-second Gaussian Aperture (Gaap) magnitudes (in AB system) of objects in each of the six Rubin filter bands in the ``#1''{test\\_v1} dataset.  These aperture magnitudes were used as the inputs for the photo-$z$\\xspace algorithms.}\n    \\label{fig:dp_mags}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/mag_i_v_redshift.pdf}\n    \\caption{1.0 arc-second Gaussian Aperture (Gaap) i-band magnitude versus redshift for all objects in the ``#1''{test\\_v1} dataset.}\n    \\label{fig:dp_mag_i_v_redshift}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[height=7in]{figures/color_v_redshift.pdf}\n    \\caption{``Adjacent band colors'', i.e., $u-g$, $g-r$, $r-i$, $i-z$, $z-y$, in 1.0 arc-second apertures versus redshift for all objects in the ``#1''{test\\_v1} dataset.  Colored lines represent the expected colors for the eight ``CWWSB'' SEDs described in Sec.~\\ref{sec:method:template}, and should very roughly show the predicted range of color evolution expected for our galaxy sample.}\n    \\label{fig:dp_color_v_redshift}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/color_v_color.pdf}\n    \\caption{Color-color plots for all objects in the ```#1''{test\\_v1} dataset.  Colored lines represent the expected colors for the eight ``CWWSB'' SEDs described in Sec.~\\ref{sec:method:template}, and should very roughly show the predicted color evolution expected for our galaxy sample.}\n    \\label{fig:dp_color_v_color}\n\\end{figure*}\n\n\\pagebreak\n\n\\subsection{Redshift reference sample}\n\\label{sec:data:reference}\n\nThe photo-$z$\\xspace estimation algorithms in RAIL require highly accurate and precise redshift estimates cross-matched to the DP1 photometric catalog to provide labeled ``#1''{training} data sets.  We created such datasets using data drawn from publicly available catalogs in the ECDFS, comprising galaxies with known spectroscopic redshifts, grism redshifts, and high-quality photo-$z$\\xspace's from deep multi-band imaging.  These training sets enable machine learning models within RAIL to learn the mapping between galaxy colors and redshifts, enabling photo-$z$\\xspace estimation for every galaxy detected in DP1.\n\n\\begin{figure*}[b]\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/redshift_reference_cat.pdf}\n    \\caption{\n        Redshift reference sample in ECDFS.\n        Left: Locations of DP1 galaxies cross-matched to objects in each reference catalog (using color scheme from middle panel).\n        Many of the sets overlap in the densely-covered GOODS-S field.\n        Middle: Redshift distribution of objects in the reference catalogs.\n        Right: Same as middle panel with a log scale on the y-axis.\n    }\n    \\label{fig:reference-sample}\n\\end{figure*}\n\nThe reference data set used to train photo-$z$\\xspace estimation algorithms can have an outsize impact on the resulting photo-$z$\\xspace estimates, particularly for machine learning based methods.  In many ways, the galaxies with known redshifts define the flux/color to distance relation by tracing out the mapping from empirical magnitudes to redshift that the algorithms ``learn''.  As such, the details of the construction of the reference sample is very important. \u00c2 In an ideal case, we would prefer to have a ``representative'' sample of redshifts, i.~e.~a fair sampling in terms of the color and magnitude distribution for all galaxies; however, due to the practicalities of spectrographs and expensive telescope time investment needed for deep spectroscopic campaigns, we must deal with incomplete training samples, particularly for faint and high redshift objects.  We must also determine which datasets contain ``secure'' redshifts that meet some confidence threshold, and whether to include datasets from grism and many-band photo-$z$\\xspace estimates that may contain a small fraction of incorrect redshift identifications.  We continue to refine our reference sample definition, and we may include or exclude additional samples as we investigate system performance, this note represents a current best effort, but the final selection will likely evolve. \u00c2 There are also some concerns of imprinted sample variance, as the deep six-band data of DP1 is concentrated in the single ECDFS field.  Future Rubin data will cover multiple widely separated deep fields containing rich spectroscopic datasets, which will mitigate these concerns, but they may be an issue for the current DP1 estimates.\n\n\n\\subsubsection{ECDFS redshift datasets}\n\\label{sec:data:prelim}\n\nWe have compiled and used two redshift samples in the ECDFS, (a preliminary version and a reference sample), consisting of spectroscopic-, grism-, and high-quality multiband photometric-redshifts (Fig.~\\ref{fig:reference-sample}).\n\nThis reference sample is used to train machine learning photo-$z$\\xspace estimators and evaluate photo-$z$\\xspace performance.\nThe component redshift catalogs (described below) were combined into a single reference catalog and their respective quality flags were homogenized by defining a redshift ``confidence'' (more on this below).\n\nWhen combining the component redshift catalogs, sources within $0.75''$ were identified as duplicates.\nFor these sources only the highest quality redshift is kept, i.e. spectroscopic redshifts are preferred over grism redshifts, which are preferred over photo-$z$\\xspace's, and higher confidence values are preferred for redshifts of the same type.\nThe redshift reference catalog was then cross-matched to the ComCam DP1 catalog using a radius of $0.75''$.\n\nConfidence, which takes values between 0.0 and 1.0, is loosely defined as the fractional probability that an individual redshift estimate is correct.\nMost of the spectroscopic sets provide these estimates for their redshifts.\nFor the few that don't we assigned the confidence 0.95.\nFor the grism and multiband photo-$z$\\xspace surveys, we set the confidence equal to $1 - f_\\text{out}$, where $f_\\text{out}$ is the reported outlier rate of these catalogs.\nTo facilitate custom quality cuts, the catalog contains flags indicating whether each redshift originates from spectroscopy (\\code{type == ''s''}), grism (\\code{''g''}), or multiband photo-$z$\\xspace (\\code{''p''}), as well as confidence values.\nNote redshifts from grism and photo-$z$\\xspace surveys, however, have larger scatter and bias than spectroscopic surveys (and possible incorrect redshifts if the redshift is based off of a single emission line), but these metrics are not captured by the confidence parameter.\nIf doing their own studies with custom reference samples, we encourage readers to investigate the details of each component survey that comprise the reference catalog and apply their own quality cuts as suit their needs.\nFor example, if studying high-redshift galaxies, you might choose to include the multiband photo-$z$\\xspace's, which increase the number of redshifts at $z > 2$ by a factor of~3 (Fig.~\\ref{fig:redshift-by-type}).\n\nWe applied conservative cuts for our fiducial analyses, specifically \\code{type == ''s''}, \\code{confidence >= 0.95}, SNR $>= 10$ in the $i$ band (using \\code{gaap1p0} fluxes).\nWe then performed a random 80\\%/20\\% train/test split on this catalog, resulting in a training set of 4803 redshifts and a test set of 1201 redshifts.\n\n\\begin{table}[!p]\n    \\centering\n    \\begin{tabular}{lllll}\n        \\hline\n        Survey & Type & Confidence & Matches& Reference \\\\\n        \\hline\n        \\hline\n        2dFGRS & s & 1.00 & 3 & \\citet{colless2001} \\\\\n               &   & 0.99 & 4 & \\\\\n               &   & 0.90$^{*}$ & 1 & \\\\\n        2dflens & s & 1.00 & 1 & \\citet{blake2016} \\\\\n        2MRS & s & 0.95 & 1 & \\citet{huchra2012} \\\\\n        6dFGRS & s & 0.98 & 2 & \\citet{jones2009} \\\\\n        3D-HST & g & 0.99 & 5 & \\citet{momcheva2016} \\\\\n               &   & 0.95 & 277 & \\\\\n        ASTRODEEP & s & 1.00 & 4165 & \\citet{merlin2021} \\\\\n                  & p & 0.97 & 8212 & \\\\\n        ASTRODEEP-JWST & s & 1.00 & 594 & \\citet{merlin2024} \\\\\n                       & p & 0.92$^{*}$ & 628 & \\\\\n                       &   & 0.90$^{*}$ & 455 & \\\\\n        CANDELS & s & 1.00 & 53 & \\citet{kodra2023} \\\\\n                & p & 0.93$^{*}$ & 6 & \\\\\n        JADES & s & 0.99 & 11 & \\citet{deugenio2025} \\\\\n              &   & 0.95 & 34 & \\\\\n              &   & 0.90$^{*}$ & 24 & \\\\\n        MOSDEF & s & 0.99 & 9 & \\citet{kriek2015} \\\\\n        NED & s & 0.95 & 847 & \\citet{helou1991} \\\\\n        OzDES & s & 0.99 & 897 & \\citet{lidman2020} \\\\\n        PRIMUS & g & 0.92$^{*}$ & 3653 & \\citet{cool2013} \\\\\n               &   & 0.85$^{*}$ & 1687 & \\\\\n        VANDELS & s & 1.00 & 196 & \\citet{garilli2021} \\\\\n        VIMOS & s & 1.00 & 499 & \\citet{balestra2010} \\\\\n                  &   & 0.95 & 43 & \\\\\n        VUDS & s & 1.00 & 9 & \\citet{tasca2017} \\\\\n             &   & 0.95 & 9 & \\\\\n             &   & 0.80$^{*}$ & 3 & \\\\\n        VVDS & s & 1.00 & 101 & \\citet{lefevre2013} \\\\\n             &   & 0.95 & 193 & \\\\\n        \\hline\n        Total & s & & 7699 & \\\\\n              & g & & 5622 & \\\\\n              & p & & 9301 & \\\\\n              & all & & 22622 & \\\\\n        \\hline\n    \\end{tabular}\n    \\caption{\n        Component surveys of the redshift reference sample.\n        Redshift type is denoted\\\\ s = spectroscopic, g = grism, p = multiband photo-$z$\\xspace.\n        Note for our fiducial analyses we applied conservative cuts on this catalog.\n        Specifically, \\code{type == ''s''}, \\code{confidence >= 0.95}, SNR $>= 10$ in the $i$ band (using \\code{gaap1p0} fluxes).\\\\\n        $^{*}$ Note: multiband photo-z redshifts and grism and spectroscopic redshifts with confidence < 0.95 were not used in any training sets employed in this note.\n    }\n    \\label{tab:reference-sample}\n\\end{table}\n\n\\begin{figure}\n    \\centering\n    \\includegraphics{figures/redshift_distribution_by_type.pdf}\n    \\caption{\n        Redshift distribution of the reference catalog by redshift type, denoted s = spectroscopic, g = grism, p = multiband photo-$z$\\xspace.\n    }\n    \\label{fig:redshift-by-type}\n\\end{figure}\n\nThe \\textit{#1}{match\\_prelim} selection used in the ``#1''{train\\_v1} and ``#1''{test\\_v1}\nincluded all spectroscopic and grism galaxies in the ``match\\_ecfds'' catalog, without applying\nany confidence cut, and only required SNR $>= 5$ in the $i$ band (using \\code{psf} fluxes).\nThis selection also dropped all galaxies with NaN magnitude in any of the six bands.\nWe randomly selected 7,000 objects for the ``#1''{train\\_v1} and assigned the remaining 2,438 to the\n``#1''{test\\_v1}  dataset. Although we used these datasets extensively in V1 of this technote,\nwe intend to update the note to use the ``#1''{train\\_v2} and ``#1''{test\\_v2} as soon as possible,\nideally in the first week of July, 2025.\n\n\n\\subsubsection{DESI Data Release 1 spectroscopic redshift dataset}\n\\label{sec:data:desi}\n\nWe also use data from the DESI Data Release \\citep{desi-dr1} to act as an independent validation data set as it overlaps the \\textbf{#1}{Rubin SV 38-7} (\\textbf{#1}{SV\\_38}) field.\nThe observations of this field are centered on the Abell 360 galaxy cluster which is located at $z=0.22$~\\citep{A360z}.\nWe cross-matched the DESI Bright Galaxy Sample (BGS) \\citep{BGS}, Emission Line Galaxy (ELG) \\citep{ELG}, and Luminous Red Galaxy (LRG) \\citep{LRG} samples against the DP1 catalog using a radius of 0.5'' producing 2728  matches with 398 from the BGS sample, 1421 from ELG, and 909 from LRG.\nThe area of overlap and the three subsamples are shown in Fig.~\\ref{fig:desi-overlap}.\nThis spans a redshift range of 0 to 1.6 and \\textit{i}-mag of 14 to 23.9 as shown in Fig.~\\ref{fig:desi-subsample-hist}; the bump at $z\\approx0.25$ can be attributed to the cluster at the center of the field.\n\n\n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/desi_sample_overlap.png}\n    \\caption{Overlap between the \\textbf{#1}{SV\\_38} sample and DESI subsamples. In all plots, the small blue dots are DP1 objects from LSSTComCam and we overlay, from left to right, the BGS, LRG, and ELG subsamples with points color-coded by redshift. Each sample probes a different redshift range and is shown with the color bar to the right of each panel.}\n    \\label{fig:desi-overlap}\n\\end{figure}\n\n\\begin{figure}]ht]\n    \\centering\n    \\includegraphics[width=.8\\linewidth]{figures/desi_sample_histogram.png}\n    \\caption{Validation set on \\textbf{#1}{SV\\_38} from DESI BRG, ELG, and LRG samples. Left plot: the redshift distribution of the matched subsample with BGS in blue, ELG in orange, LRG in green, and the total matched distribution in black. Right plot: \\textit{i}-band magnitude as measured by LSSTComCam versus spectroscopic redshift for all DESI matches with subsamples shown using the same color scheme as left plot.}\n    \\label{fig:desi-subsample-hist}\n\\end{figure}\n\nIf an object was included in multiple samples, when matching we restrict to the one with the largest weight as calculated by DESI DR1.\nThe \\textbf{#1}{SV\\_38} field was observed in \\textit{g} (44 visits), \\textit{r} (55 visits), \\textit{i} (57 visits) and \\textit{z} (27 visits) bands restricting our validation to the 4 band models.\nFurthermore, the incomplete overlap with the BGS sample limits our ability to validate on redshifts below $z=0.5$.\n\n\n\\section{Methodology}\n\\label{sec:method:0}\n\nWe used the RAIL as the core tool for training and applying photo-$z$\\xspace estimation models.   We also used RAIL to evaluate the model performance through a suite of diagnostic metrics using photo-$z$\\xspace point estimates, including redshift bias, scatter (e.g., normalized median absolute deviation), and catastrophic outlier rate and to make diagnostic plots of the algorithm's performance.  Specifically, we used the methodology described below to evaluate all the algorithms listed in Tab.~\\ref{tab:alg}.\n\nAs part of the Rubin photo-$z$\\xspace roadmap process, \\code{KNN} and \\code{BPZ} were chosen as ``testing algorithms'' from the shortlist of algorithms considered in~\\citep{DMTN-049}, the expectation is that these will supported by project data management team for Data Preview 2,  while the others will be supported by the wider community, the RAIL development team and DESC collaboration.\n\n\n\\begin{table*}[ht]\n\\centering\n\\begin{tabular}{lll}\n \\hline\n    Algorithm name  & Home package & Reference\\\\\n \\hline\n \\hline\n \\multicolumn{3}{c}{Project Supported Testing} \\\\\n  \\code{BPZ} & \\href{https://github.com/LSSTDESC/rail_bpz}{\\code{rail-bpz}} & \\citet{Benitez:2000}\\\\\n \\code{KNN} & \\href{https://github.com/LSSTDESC/rail_sklearn}{\\code{rail-sklearn}} & RAIL Paper\\\\\n \\multicolumn{3}{c}{Community Supported} \\\\\n \\code{CMNN} & \\href{https://github.com/LSSTDESC/rail_cmnn}{\\code{rail-cmnn}} & \\citet{Graham:2018}\\\\\n \\code{DNF} & \\href{https://github.com/LSSTDESC/rail_dnf}{\\code{rail-dnf}} & \\citet{2016MNRAS.459.3078D}\\\\\n \\code{FlexZBoost}  & \\href{https://github.com/LSSTDESC/rail_flexzboost}{\\code{rail-flexzboost}} & \\citet{Izbicki:2017}\\\\\n \\code{GPz} & \\href{https://github.com/LSSTDESC/rail_gpz_v1}{\\code{rail-gpz-v1}} & \\citet{Almosallam:2016}\\\\\n \\code{LePHARE} & \\href{https://github.com/LSSTDESC/rail_lephare}{\\code{rail-lephare}} & \\citet{1999MNRAS.310..540A}\\\\\n \\code{TPZ} & \\href{https://github.com/LSSTDESC/rail_tpz}{\\code{rail-tpz}} & \\citet{Carrasco-Kind:2013}\\\\\n \\hline\n\\end{tabular}\n\\caption{\nSummary of the pre-wrapped estimators/summarizers/classifiers used in this paper and described detail in~\\citep{RAIL}.}\n\\label{tab:alg}\n\\end{table*}\n\nFor each algorithm, we trained photo-$z$\\xspace models using the reference datasets described in Sec.~\\ref{sec:data:reference}.   Specifically, we used the \\code{rail\\_project} package (see \\ref{sec:method:rail_project} to run RAIL\u00e2\u20ac\u2122s \\href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/pz_all.py}{PzPipeline}.  The pipeline consists of ``Informing'' or training the models on the ``training'' dataset, and using those models in ``Estimation'' and ``Evaluation'' stages on the reserved ``test'' dataset to evaluate the algorithm performance.  We also used \\code{rail\\_project} to run RAIL\u00e2\u20ac\u2122s  \\href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/estimate_all.py}{EstimatePipeline}, to perform the photometric redshift estimation on the unlabeled data sets for all of the algorithms.\n\nIn this work we are only using the magnitudes in the six (or four) available Rubin bands as inputs to the photometric estimation.  We do not use other inputs, such as object size or morphology, or photometry from other surveys.   As stated in\nSec.~\\ref{sec:data:dp1:properties}, we systematically use the \\texttt{gaap1p0} version of the fluxes, as these are considered the most reliable for color estimation.\n\n\n\\subsection{Template fitting based estimators}\n\\label{sec:method:template}\n\nRAIL\u00e2\u20ac\u2122s template-based fitting algorithms (\\code{Lephare} and \\code{BPZ}, see references in Tab.~\\ref{tab:alg} for more details) estimate photometric redshifts by comparing observed galaxy photometry to a set of predefined theoretical or empirical galaxy templates.  These templates represent a range of galaxy spectral energy distributions (SEDs) that are meant to span the expected range of galaxy types observed in the Universe.  Synthetic model fluxes are computed by red-shifting each SED to a set grid of values and convolving with the Rubin filter curves,  which characterizes the expected variation in observed colors with redshift.  Our algorithms calculate the chi-square/likelihood for each SED at each grid point by comparing the model fluxes in our photometric bands to the observed fluxes and uncertainties.  This process enables the algorithm to determine the relative likelihood for each redshift for a given galaxy by identifying the template that best matches its observed color signature.  An optional empirical Bayesian prior can also be applied to produce a posterior probability rather than a straight likelihood if information on the expected distributions are available.  The training phase for these algorithms consist mostly of preparing pre-computed tables for the expected fluxes in each filter band for each SED template.\n\nTwo sets of templates are included in the \\code{rail\\_base} software package and used in this note: the ``CWWSB'' templates that are the default templates used by \\code{rail\\_bpz} and described in \\citet[]{Coe:06}, consisting of eight total SEDs, one Elliptical template, two Spiral templates, and five Irregular/Starburst template.  In this note, these SEDs are used to compute synthetic colors that we compare to the observational data in Figures~\\ref{fig:dp_color_v_redshift} and~\\ref{fig:dp_color_v_color}, but are otherwise not used.  The second template set consists of those described in \\citet[]{Ilbert:09}, consisting of 31 synthetic SEDs (including some that are ``interpolated'' between adjacent templates by taking the mean of the two SEDs).  These SEDs are included with \\code{rail\\_lephare} as ``COSMOS\\_mod.list'' in the \\code{lephare-data} package.  These SEDs are used by both template codes \\code{rail\\_bpz} and \\code{rail\\_lephare}.  The 31 base SEDs contain no internal dust extinction, \\code{rail\\_lephare} is configured to include dust automatically, while \\code{rail\\_bpz} required dust to be added explicitly, and additional SED templates that include internal extinction added to the input SED list. \\code{LePhare} also includes a set of stellar and AGN SEDs, which are available in the \\code{lephare-data} package.\n\n\n\\subsection{Machine learning based estimators}\n\\label{sec:method:machine_learning}\n\nRAIL\u00e2\u20ac\u2122s machine learning algorithms (\\code{CMNN}, \\code{DNF}, \\code{FlexZBoost}, \\code{GPZ}, \\code{KNN}, \\code{TPZ}) are described in detail in the publications listed in Tab.~\\ref{tab:alg}.  In short these algorithms attempt to perform a regression analysis to estimate the redshift from the input photometric data.   It is a well-known limitation of machine learning algorithms that they exhibit biases when presented with non-representative data, or are asked to extrapolate results outside region of their training data.\n\n\n\\subsection{Analysis framework and bookkeeping software}\n\\label{sec:method:rail_project}\n\nThe \\code{rail\\_projects} software package within the RAIL ecosystem provides an essential framework for managing and organizing large-scale photometric redshift estimation workflows.  It acts as a project management and book-keeping tool that helps users streamline their research, especially when working with complex or large datasets, like those associated with the Rubin DP1 data.  The primary focus of \\code{rail\\_projects} is to offer a systematic way to track different stages of data processing, model training, evaluation, and results across multiple experiments, ensuring that all tasks are well-documented and reproducible.\n\nAdditionally, \\code{rail\\_projects} facilitates the management of large datasets by organizing data into structured directories and providing interfaces for batch processing.  It allows users to scale up their work to handle not only large catalogs of objects but also multiple datasets and redshift estimation tasks.  The package ensures that datasets and models are kept in sync across various stages, from raw input data to intermediate results to final outputs, and makes it easier to systematically export data coherent products.\n\n\\subsection{Data exploration and algorithm optimization}\n\\label{sec:method:optimization}\n\nWe explored dozens of different configuration settings, covering analysis choices such as which flux measurements to use, the machine learning hyper-parameters, which sets of SED templates to use, among others.   The \\href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1.yaml} configuration file (see Sec.~\\ref{sec:products:configuration}) captures the set of configurations that we tested and labels each set into an analysis ``flavor'' to facilitate bookkeeping.\n\nAfter examining the performance of the algorithms under different configurations, we settled on a set of optimized parameters for each algorithm and on the \\code{gaap\\_1p0} fluxes to produce the best-effort catalogs for DP1.   These optimized configurations parameters are captured in the \\href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1\\_v1.yaml} configuration file.\n\n\n\\subsection{Production of redshift catalogs}\n\\label{sec:method:redshift_catalogs}\n\nWe produced photo-$z$\\xspace catalogs in two different software frameworks, both to test the software pipelines as well as to facilitate using associated tools to distribute the resulting data products.\n\n\n\\subsubsection{Catalogs in the \\code{rail\\_projects} framework}\n\\label{sec:method:redshift_catalogs:rail}\n\nWe used \\code{rail\\_project} to run RAIL\u00e2\u20ac\u2122s  \\href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/estimate_all.py}{EstimatePipeline}, to perform the photometric redshift estimation on the unlabeled data sets for all of the algorithms.\n\nSpecifically, we used \\code{rail\\_project} to run all of the configuration flavors defined in the \\href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1.yaml} and \\href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1\\_v1.yaml} configuration files.\nThe resulting data products are internally available as files at the USDF and NERSC as described in App.~\\ref{sec:distribution:files}.   It is expected some of the products will be distributed via other methods in the near future (see App.~\\ref{sec:distribution:linea} and App.~\\ref{sec:distribution:lsdb}).\n\n\n\\subsubsection{Catalogs in the Rubin data management framework}\n\\label{sec:method:redshift_catalogs:dm}\n\nWe also used the \\href{https://github.com/lsst-dm/meas_pz}{\\code{meas\\_pz}} and \\href{https://github.com/lsst-dm/meas_pz}{\\code{meas\\_pz\\_extensions}} software packages\nto create photo-$z$\\xspace catalogs in the Rubin data management framework.\n\nSpecifically, we imported trained models produced in the \\code{rail\\_project} into the DP1 data Butler and produced photo-$z$\\xspace estimates for every object in DP1 for each algorithm.\n\nWe did this for the \\texttt{baseline} analysis flavor, (consisting of ``out-of-the-box'' algorithms, with all settings at default values) and the optimized 6 band (\\texttt{dp1\\_optimze}) flavor defined in \\href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1\\_v1.yaml}.\nThe resulting data products are internally available via data Butlers at USDF and NERSC as described in App.~\\ref{sec:distribution:butler}.   As with the \\code{rail\\_projects} created catalogs, it is expected some of the products will be distributed via other methods in the near future (see App.~\\ref{sec:distribution:linea} and App.~\\ref{sec:distribution:lsdb}).\n\n\n\\section{Performance}\n\\label{sec:performance:0}\n\nWe evaluated all the algorithms listed in Tab.~\\ref{tab:alg} for both scientific and technical performance.\n\n\\subsection{Redshift estimator performance}\n\\label{sec:performance:pz}\n\nWe primarily evaluated the performance using the ``test\\_v1'' catalog which consist of 2,437 galaxies randomly drawn from the cross-match between the DP1 object catalog in ECDFS with the reference redshifts described in Sec.~\\ref{sec:data:reference}.  Additionally, we cross matched the DP1 object catalog in the \\textbf{#1}{SV\\_38} field with the DESI DR1 BGS, LRG and ELG galaxies as a secondary validation set (``test\\_DESI'').\n\nSpecifically, we ran the \\href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/pz_all.py}{PzPipeline}\n(Inform $\\rightarrow$ Estimate $\\rightarrow$ Evaluate) to train models for per-object $p(z)$ estimation on the training data set, use those models to obtain photo-$z$\\xspace estimates for the test data set, and then evaluate the performance of the photometric point-estimate of the redshift against the spectroscopic estimates.\n\nFor each algorithm, we produce a set of performance monitoring plots, described in Sec.~\\ref{sec:products:peformance_plots}. In Fig~\\ref{fig:perf_gold}, we show examples of these performance monitoring plots for two algorithms: \\code{knn} and \\code{bpz} for the 6-band models and using the mode for the specific point estimate. Fig.~\\ref{fig:perf_gold_4_band} shows the performance monitoring of \\code{knn} and \\code{bpz} when 4-bands are used. In the scattering plot, the mean, standard deviation, 3$\\sigma$ outliers and absolute outliers of\n\\begin{equation}\n\\label{eq:dz}\n    \\Delta z = \\frac{z_{\\rm phot} - z_{\\rm spec}}{1+z_{\\rm spec}}\n\\end{equation}\nare shown in legend. We summarized these statistics in Table~\\ref{tab:photoz_metrics}.\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/zestimate_v_ztrue_hist2d_knn.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/zestimate_v_ztrue_hist2d_bpz.png} \\\\\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_redshift_knn.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_redshift_bpz.png} \\\\\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_mag_knn.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_mag_bpz.png}\n    \\caption{Estimator performance on the ``gold'' (six-band') dataset.  Top row: photometric point estimate of the redshift versus spectroscopic redshift for \\code{KNN} (left) and \\code{bpz} (right).   Middle row: performance metrics, (width and bias of residual, and outlier rate) versus spectroscopic redshift.    Bottom row, performance metrics versus i-band magnitude.}\n    \\label{fig:perf_gold}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/zestimate_v_ztrue_hist2d_knn_4.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/zestimate_v_ztrue_hist2d_bpz_4.png} \\\\\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_redshift_knn_4.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_redshift_bpz_4.png} \\\\\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_mag_knn_4.png}\n    \\includegraphics[width=0.45\\linewidth]{figures/biweight_stats_v_mag_knn_4.png}\n    \\caption{Estimator performance on the ``gold\\_4\\_band'' (four-band') dataset.  Top row: photometric point estimate of the redshift versus spectroscopic redshift for \\code{KNN} (left) and \\code{bpz} (right).   Middle row: performance metrics, (width and bias of residual, and outlier rate) versus spectroscopic redshift.    Bottom row, performance metrics versus i-band magnitude.}\n    \\label{fig:perf_gold_4_band}\n\\end{figure*}\n\n\\begin{table}[ht]\n\\centering\n\\caption{Performance metrics for photo-$z$\\xspace algorithms using 6-band data, with 4-band results shown in parentheses.}\n\\begin{tabular}{lcccc}\n\\hline\n\\textbf{Algorithm} & \\textbf{Bias} & \\textbf{$\\sigma$} & \\textbf{3$\\sigma$ Outlier Rate} & \\textbf{$\\Delta z>0.2$ Outlier Rate} \\\\\n\\hline\nFlexZBoost & 0.000 (0.000) & 0.0246 (0.0274) & 0.215 (0.221) & 0.113 (0.124) \\\\\nkNN        & -0.002 (-0.000) & 0.0301 (0.0285) & 0.205 (0.245) & 0.128(0.147) \\\\\nCMNN       & 0.000 (-0.002) & 0.0369 (0.0729) & 0.227 (0.212) & 0.160 (0.226) \\\\\nDNF        & -0.002 (-0.001) & 0.041 (0.0327) & 0.189 (0.215) & 0.138 (0.121) \\\\\nTPZ        & -0.001 (-0.002) & 0.050 (0.0524) & 0.154 (0.156) & 0.117 (0.127) \\\\\nGPz        & 0.032 (0.018) & 0.166 (0.106) & 0.056 (0.110) & 0.260 (0.198) \\\\\nBPZ        & -0.018 (-0.015) & 0.0425 (0.060) & 0.198 (0.197) & 0.146 (0.186) \\\\\nLePhare    & -0.012 (-0.015) & 0.0344 (0.0699) & 0.207 (0.175) & 0.139 (0.185) \\\\\n\\hline\n\\end{tabular}\n\\label{tab:photoz_metrics}\n\\end{table}\n\n\n\n\\subsubsection{Redshift estimation quality flags}\n\\label{sec:performance:pz:flag}\n\nApplying a simple cut on the RMS of the $p(z)$ distribution can dramatically reduce the catastrophic outlier rate.  In Fig.~\\ref{fig:perf_quality_cut} we show how the efficiency and purity obtained on the test sample varies with a single additional cut, $x$ in $\\sigma_{p(z)} < x$.   In Fig.~\\ref{fig:scatter_quality_cut} we show how applying a cut at $\\sigma_{p(z)} < 0.15$ improves the scatter of the photometric redshift point-estimate versus spectroscopic redshift distribution.  As fainter objects and objects at higher redshift often have larger $p(z)$ RMS values, cuts on RMS will likely result in relative shifts in the magnitude and redshift distribution depending on the cut value.\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/efficiency.pdf}\n    \\includegraphics[width=0.45\\linewidth]{figures/purity.pdf} \\\\\n    \\includegraphics[width=0.45\\linewidth]{figures/purity_v_effic.pdf} \\\\\n    \\caption{Efficiency (top left) and ``purity'', i.e., fraction of objects with $\\frac{\\delta z}{1 + z_{\\rm spec}} < 0.20$) (top right) versus quality cut, $x$ in $\\sigma_{p(z)} < x$.   Bottom, purity version efficiency with cut value shown by the color scale.   The red star shows the point for a cut value  $\\sigma_{p(z)} < 0.15$.}\n    \\label{fig:perf_quality_cut}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/tpz_scatter_orig.pdf}\n    \\includegraphics[width=0.45\\linewidth]{figures/tpz_scatter_clean.pdf} \\\\\n    \\caption{Estimator performance for \\code{TPZ} without (left) and with (right) a quality cut of $\\sigma_{p(z)} < 0.15$.}\n    \\label{fig:scatter_quality_cut}\n\\end{figure*}\n\n\n\\subsubsection{Validation in the \\textbf{#1}{SV\\_38} field}\n\nWe cross-matched our photo-$z$\\xspace estimates with the DESI DR1 LSS galaxies (BGS, LRG, and ELG) in the \\textbf{#1}{SV\\_38} field. This cross-matched catalog can serve as additional validation for our photo-$z$\\xspace results.  In Fig.~\\ref{fig:sv_validation}, we show the median photometric redshift estimates versus the DESI spectroscopic redshifts all eight tested photo-$z$\\xspace algorithms.  Each panel corresponds to a different algorithm, allowing us to visually assess the bias, scatter, and potential outlier behavior across a wide redshift range. Overall, the agreement with DESI DR1 spectroscopic redshifts provides a robust sanity check on the performance of our methods in the early LSST data regime.\n\n\\begin{figure*}\n\\centering\n\\includegraphics[width=0.32\\linewidth]{figures/fzboost_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/knn_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/cmnn_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/dnf_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/tpz_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/gpz_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/bpz_mode_desi.png}\n\\includegraphics[width=0.32\\linewidth]{figures/lephare_mode_desi.png}\n\\caption{Mode photometric redshift estimates versus DESI DR1 spectroscopic redshifts for galaxies in the \\textbf{#1}{SV\\_38} cross-matched sample. Each panel shows results from a different photo-$z$\\xspace algorithm: FlexZBoost, kNN, CMNN, DNF, TPZ, GPz, BPZ, and LePhare (from left to right, top to bottom). These comparisons provide an external validation of photo-$z$\\xspace performance using Large-Scale Structure spectroscopic redshifts samples DESI.}\n\\label{fig:sv_validation}\n\\end{figure*}\n\n\n\n\\subsection{Technical performance}\n\\label{sec:performance:technical}\n\nTab.~\\ref{tab:tech_perf} shows compute times and file sizes for both the training and estimation phases of the analysis.    The metrics from the training phase were taken from running the algorithm's ``Inform'' stages on USDF on the ``training\\_v1'' dataset of ~7,000 objects.    The metrics from the estimation phase were taken from algorithm's ``Inform'' stages on USDF on the ``test\\_v1'' datasets of ~2,437 objects.\n\n\\begin{table*}\n\\centering\n\\begin{tabular}{lllll}\n \\hline\n  Algorithm name  & \\multicolumn{2}{c}{Training}  &  \\multicolumn{2}{c}{Estimation} \\\\\n   & Time [s] & Model Size [MB] &  Speed [ms / object] & Data Size [b / object] \\\\\n \\hline\n \\hline\n \\multicolumn{5}{c}{Project Supported} \\\\\n  \\code{BPZ} & $< 5$ & 1 & 1.5-10 & $\\sim$ 2400\\\\\n \\code{KNN} & 8 - 30 & 1 & 0.6-1.5 & $\\sim$ 240 \\\\\n \\multicolumn{5}{c}{Community Supported} \\\\\n \\code{CMNN} &  $< 5$ & 1 & 2.4 & 54 \\\\\n \\code{DNF} &  $< 5$ & 2 & 0.6 & $\\sim$ 2400 \\\\\n \\code{FlexZBoost}  & 55 - 100 & 35 - 50 & 4-13 & $\\sim$ 2400\\\\\n \\code{GPz} & 10 - 15 & 1 & < 0.5 & 32 \\\\\n \\code{LePHARE} & 300 - 600 & 1 & 50 - 180 & $\\sim$ 2400 \\\\\n \\code{TPZ} & 5-20 & 7 - 300 & 7 - 120 & $\\sim$ 2400 \\\\\n \\hline\n\\end{tabular}\n\\caption{\n  Algorithm compute times and files sizes.   The algorithms were trained on 7000 objects and evaluated on 2,437 objects.  The variations shown reflect the differences in processing times with different sets of hyper-parameters.\n}\n\\label{tab:tech_perf}\n\\end{table*}\n\nWe note that the technical performance requirements depend heavily on the scientific use case.  For example, in supernova cosmology, the number of objects will be in the 100's of thousands, while for weak-lensing cosmology, it will be in the billions.  Accordingly, these give very different constraints on the required processing speed of the photo-$z$\\xspace estimation.  While seconds per object is supportable for supernova cosmology, weak-lensing will require processing times in the milliseconds ($ms$) per object range.\n\n\n\\section{Limitations and Caveats}\n\\label{sec:limitations:0}\n\nThe photo-$z$\\xspace estimates described in this note were done on a best-effort basis by members of the ``Photo-z Science Unit'' and are not official Rubin data products.  As such, the release of the various DP1-related data products comes with a number of caveats.\n\n\\begin{itemize}\n\\item{The size and depth of the training set seriously limits the robustness of the training past a redshift of $z \\simeq 1.5$.  See in particular Fig.~\\ref{fig:dp_mag_i_v_redshift}.}\n\\item{In general, photo-$z$\\xspace algorithms do not perform well with objects with marginal detections or with non-detections in several bands.  Simply put, the photometric uncertainties in such objects often overwhelms the information that is present and the photometric estimates are very uncertain.  See Fig.~\\ref{fig:faint_object_pdf} for an example of the PDF of such an object.   Similarly, see, Fig~\\ref{fig:faint_objects} as an illustration of how the accuracy of a photo-$z$\\xspace point-estimate degrades significantly for faint objects.}\n\\item{Taking points (1) and (2) together, we do not advise to use any of the provided DP1 photo-$z$\\xspace estimates without applying cuts on the detection significance or the width of the $p(z)$ distribution, or both.}\n\\item{While we did put some work into optimizing the performance of the various algorithms, this was by no means comprehensive, and we urge caution in drawing any conclusions about the relative merits of the algorithms.}\n\\item{The training and test sets were drawn from the same set of spectroscopically matched objects.  As such, the training set is fairly representative of the test set.   On the other hand, the full DP1 catalog does not have any spectroscopic selections applied, so the training and test sets will not be representative of the full DP1 data set.}\n\\end{itemize}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/bad_pdf.pdf}\n    \\caption{Example of a $p(z)$ distribution for a faint object is not detected in all bands.  (In this case the object was only significantly detected in 'g' and 'r' bands).}\n    \\label{fig:faint_object_pdf}\n\\end{figure*}\n\n\\begin{figure*}\n    \\centering\n    \\includegraphics[width=0.45\\linewidth]{figures/tpz_scatter_faint.pdf}\n    \\caption{Point-estimates versus spectroscopic redshifts for all galaxies in the reserved test set with $m_{i} > 23.5$, showing the degradation in estimation performance for faint objects.}\n    \\label{fig:faint_objects}\n\\end{figure*}\n\n\n\\section{Summary and Conclusion}\n\\label{sec:summary:0}\n\nThis note describes an initial calculation of photometric redshifts on the Rubin Data Preview 1 dataset using the tools and workflows developed specifically for this purpose by the Photo-z Science Unit.  These early results are very promising, we show that we can successfully match Rubin data with spectroscopic samples in the ECDFS field with deep six-band Rubin coverage to create a reference sample and run our software pipelines to generate a catalog of individual object redshifts consisting of both point 1D redshift PDFs and point estimate redshifts.  We show results for eight photo-$z$\\xspace algorithms using a reserve set of redshifts, and see that photo-$z$\\xspace performance is in-line with expectations both in terms of our redshift predictions and for compute times.  We also test our estimates against an independent set of redshifts from the \\textbf{#1}{SV\\_38} field with shallower coverage and imaging in only four of the six Rubin bands.  We describe available data products and anticipated methods to access them.  Overall, this is a very successful initial test of photo-$z$\\xspace pipelines.\n\nHowever, work will continue on several fronts to further optimize the performance of our redshift predictions.  As mentioned earlier in the note, the definition of the true redshift reference sample used to train our algorithms has a large impact on results, being the ``truth'' used to define the flux/color-to-redshift mapping that is inherent to photo-$z$\\xspace estimation.  We will work to refine our reference sample definition, which objects to include/exclude based on quality flags, explore the tradeoffs of including grism and many-band photo-$z$\\xspace estimates with larger redshift uncertainties in our training sample, and other such effects.  As more and more Rubin data is taken, areal coverage is increasing, including coverage of additional deep calibration fields with existing spec-z datasets.  This will naturally improve photo-$z$\\xspace performance.  Expansion of reference redshifts will also enable the development of improved object flagging for identifying which redshifts are trustworthy and those which are likely to be incorrect.\n\nWe will also continue to examine the Rubin photometry and evaluate the performance of multiple measurement algorithms.  In this note we used Gaussian Aperture (Gaap) fluxes and magnitudes, as they are expected to produce consistent colors.  We will undertake a thorough exploration of multiple flux measurements (e.~g.~cModel, Sersic, additional Gaap apertures) to test which combinations lead to the best photo-$z$\\xspace estimates, as well as combinations like using multiple aperture magnitudes that may contain information on the galaxy light profile that could help to constrain redshift.  As we are still in the engineering and testing phase of the project, there is ongoing work to characterize system performance, and improved understanding of the system will likely lead to better photo-$z$\\xspace performance.  For example, there may be some hints that u-band fluxes are overestimated and u-band uncertainties underestimated at faint magnitudes (see the high redshift u-g colors in Fig.~\\ref{fig:dp_color_v_redshift} and figures in~\\citet{RTN-095}).  DP1 data was obtained using LSSTComCam, while future data releases will use LSSTCam, and thus performance for DP2 and beyond may be shaped by slight differences between the two instruments.\n\nIn this analysis, while there was some optimization of code-specific parameters for the individual estimators, e.~g.~the number of neighbors used for \\code{KNN}, the number of trees used for \\code{TPZ}, it was not comprehensive.  In addition, the optimal values will likely change slightly as we refine both our spectroscopic reference sample and our photometric inputs.  A thorough exploration of the code parameters will happen as we converge on our final photometric and spectroscopic setup.\n\nAs stated in the introduction, we expect feedback from science users as they explore the data and discover issues that we have not anticipated, and that we will incorporate that feedback in future work.\n\nKey takeaway: while very promising, these results are far from final, there is ongoing work to optimize photo-$z$\\xspace performance.  We have plans in place and will continue to refine as new data arrives, and these plans should lead to improved redshift performance.\n\n\\pagebreak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\appendix\n\n\n\\section{Data products}\n\\label{sec:products:0}\n\nIn the course of this work, we generated several data products, including redshift estimates and a variety of others that can be used to reproduce those estimates and to facilitate thorough evaluation of the algorithm performance.  These products include: configuration files ( Sec.~\\ref{sec:products:configuration}), ancillary inputs (Sec.~\\ref{sec:products:algo_files}), trained models (Sec.~\\ref{sec:products:models}), redshift estimates (Sec.~\\ref{sec:products:qp_ensembles}), summary statistics (Sec.~\\ref{sec:products:summary_statistics}, and performance monitoring plots (Sec.~\\ref{sec:products:peformance_plots}), all of which are essential for understanding the quality of the photometric redshift estimates and for refining the algorithms.   Together, these data products provide a comprehensive framework for conducting, managing, and evaluating photometric redshift estimation workflows in Rubin DP1.  They ensure that the process is not only scientifically rigorous but also organized and reproducible, enabling effective collaboration and ongoing refinement of photometric redshift techniques.\n\n\n\\subsection{Configuration files}\n\\label{sec:products:configuration}\n\nThe configuration files, collected \\href{https://github.com/lsstdesc/rail_project_config}{in the GitHub \\code{rail\\_project\\_config}} repository, provide the necessary parameters and settings to control the various stages of the redshift estimation process, are a key element of \\code{rail\\_projects} workflow.  These files typically include specifications for the photometric bands used (e.g., g, r, i, z), the algorithm choices (e.g., template fitting or machine learning methods), details about data pre-processing, such as feature normalization and handling of missing data.  These configuration files also specify the training and validation dataset splits, hyper-parameters for machine learning models, and paths for input/output data.  These files are essential for ensuring reproducibility and for sharing the exact settings used in different redshift estimation runs, enabling other researchers to replicate or extend the analysis.\n\n\n\\subsection{Ancillary input files}\n\\label{sec:products:algo_files}\n\nIn addition to the configuration files, we require ancillary inputs such as the galaxy spectral energy distribution (SED) templates and the filter throughputs.  Galaxy SED templates are collections of theoretical or observed spectra for galaxies at different redshifts and with different properties (e.~g.~, galaxy type, age, star formation history).  These templates are used by template-fitting algorithms to model the expected galaxy colors as a function of redshift, allowing for the estimation of photometric redshifts by comparing observed colors to those predicted by the templates.  Two SED sets are employed in this note, they are each described in Section~\\ref{sec:method:template}.\n\nThe filter throughputs specify the characteristics of the fiducial observational filter transmission curves, and are used in Rubin DP1, including their corresponding central wavelengths.  These filter curves are employed in calculating the synthetic fluxes or magnitudes expected from each of the SED templates used in template-fitting algorithms, and for matching observational data to predicted theoretical values, e.~g.~the predicted colors shown in Figure~\\ref{fig:dp_color_v_redshift}.\n\n\n\\subsection{Estimator data models}\n\\label{sec:products:models}\n\nAfter training, the trained models for each photometric redshift estimation algorithm are stored as serialized files, either in Pickle (for Python-based models) or YAML (for model configurations) format.  These models encapsulate the learned relationships between photometric features (such as magnitudes and colors) and redshift values, allowing them to be applied to new data for redshift estimation.  These files store the final state of the model, including the weights, biases, and other learned parameters for machine learning models.  In the case of template-fitting methods, the corresponding model files may include the template sets and the fitting parameters.  The Pickle or YAML format ensures that the models can be easily loaded, applied to new datasets, and evaluated in future studies.\n\n\n\\subsection{Redshift estimates stored as QP ensembles}\n\\label{sec:products:qp_ensembles}\n\nThe per-object redshift estimates generated by the photometric redshift algorithms are stored in \\code{qp} files.  These files serve as containers for storing the redshift predictions for each object in the dataset before any detailed statistical analysis or final reporting.  In the qp files, each galaxy\u00e2\u20ac\u2122s redshift estimate is stored in a format that is compatible with the algorithm providing the estimate.   Specifically, for each object we store distribution $p(z)$, which, depending on the algorithm, maybe represent a posterior probability, a likelihood, a conditional likelihood, or just a hunch as to redshift of the object in question.   These \\code{qp} files are designed to be lightweight and easy to query, allowing users to quickly retrieve the redshift estimates for individual objects.  The structure of \\code{qp} files is optimized for efficient access and data retrieval, making it easier for users to process and analyze large numbers of photometric redshift estimates across large datasets like Rubin DP1.  Additional information, including usage examples, about \\code{qp} and \\code{qp} files is available at \\href{https://qp.readthedocs.io/en/main/}{https://qp.readthedocs.io/en/main/}.\n\n\n\\subsection{Per-Object Point Estimates}\n\\label{sec:products:summary_statistics}\n\nIn addition to the raw redshift estimates, the \\code{qp} files also store per-object point estimates in the form of an ancillary table.  These estimates include crucial information about the quality and reliability of each photometric redshift estimate, such as the uncertainty in the redshift prediction (e.g., the confidence interval or standard deviation or, the likelihood score (in the case of probabilistic models).   This table will eventually includes flags for identifying objects with low-confidence estimates or those that may be outliers.  These summary statistics are important for evaluating the overall performance of the redshift estimation algorithms on an object-by-object basis and are often used to filter out low-quality or problematic redshift estimates before conducting larger statistical analyses.\n\nWe also generate meta catalog file that collects the Object ID, magnitude information, and point estimates. The point estimates are named by ``\\{algorithm\\}\\_z\\_\\{point estimate name\\}''.\nHere is a list of the point estimates and summary statistics that are stored for each algorithm and the corresponding column names:\n\\begin{enumerate}\n    \\item \\textbf{mean}: is the per-object expectation of redshift given by the PDF.\n    \\item \\textbf{median}: is the 50\\% percentile of the PDF.\n    \\item \\textbf{mode}: is the redshift that yields maximum PDF evaluated on 301 grid points between $z=0$-$3$.\n    \\item \\textbf{err68\\_lower(upper)}: is the 16th (84th) percentile of the per-galaxy PDF, which correspond to the 1$\\sigma$ confidence interval.\n    \\item \\textbf{err95\\_lower(upper)}: is the $2.5$th ($97.5$th) percentile of the per-galaxy PDF, which correspond to the 2$\\sigma$ confidence interval.\n\\end{enumerate}\nFig.~\\ref{fig:pdf} shows an example of the $p(z)$ distribution, point-estimates and summary statistics for a single object.\n\nYes.\\begin{figure*}\n    \\centering\n    \\includegraphics[width=1.0\\linewidth]{figures/pdf.pdf}\n    \\caption{Single object $p(z)$ estimate, showing both the PDF, and the CDF, as well as the summary statistics described in the text.}\n    \\label{fig:pdf}\n\\end{figure*}\n\n\n\\subsection{Performance Monitoring Plots}\n\\label{sec:products:peformance_plots}\n\nFinally, we produced standardized performance monitoring plots as part of the photometric redshift workflow.  These plots provide visual representations of the model's performance, allowing users to assess how well the redshift estimates align with the true redshifts from the spectroscopic training data.  Common plots include:\n\n\\begin{itemize}\n\\item{Input dataset characterization plots, as shown in Sec.~\\ref{sec:data:dp1:properties}.}\n\\item{Scatter plots to visualize the relationship between the predicted and true redshifts, highlighting any systematic biases or non-linearities.}\n\\item{Redshift comparison plots, e.g., the bias or width of the redshift residuals, $\\frac{z_{\\rm phot} - z_{\\rm spec}}{1 + z_{\\rm spec}}$, as a function of redshift or object magnitude.}\n\\end{itemize}\n\nTo robustly summarize the distribution of residuals while minimizing the influence of outliers, we compute biweighted statistics following a two-step procedure. First, we apply an iterative $3\\sigma$ clipping to the input array using \\texttt{scipy.stats.sigmaclip}, repeating the clipping process \\texttt{nclip} times (default is 3). This removes extreme outliers before computing robust estimators. We then calculate the \\textit{biweight location} and \\textit{biweight scale} of the clipped subset using the \\texttt{astropy.stats} functions, which yield robust analogs to the mean and standard deviation, respectively.\n\nIn addition, we compute two outlier rates: the \\textit{relative outlier rate}, defined as the fraction of values in the original sample that deviate from zero by more than $3\\times$ the biweight scale, and the \\textit{absolute outlier rate}, defined as the fraction of values exceeding a fixed threshold set by \\texttt{self.config.abs\\_out\\_thresh}. This framework provides both robust central moments and a diagnostic of extreme deviations in the full sample.\n\nExamples of the two latter types of plots for the \\texttt{BPZ} and \\texttt{KNN} algorithms are shown in Sec.~\\ref{sec:performance:0}\n\n\n\\section{Data Distribution}\n\\label{sec:distribution:0}\n\nTo support both the Rubin community and the DESC, we will distribute these data products in several different ways:\n\\begin{enumerate}\n\\item{Via the Rubin Data Butler (see Sec.~\\ref{sec:distribution:butler}).}\n\\item{Via the Photo-z Server (see Sec.~\\ref{sec:distribution:linea}).}\n\\item{Directly as files at the USDF and NERSC (see Sec.~\\ref{sec:distribution:files}).}\n\\item{Via LSDB (see Sec.~\\ref{sec:distribution:lsdb})}\n\\end{enumerate}\n\nIn each of these distribution mechanisms there are a number of metadata that are used as fields in defining specific data products.  In particular:\n\n\\begin{itemize}\n\\item{\\textbf{algo}: specifies a particular photo-z estimation algorithm (see Tab.~\\ref{tab:alg}),}\n\\item{\\textbf{selection}: specifies a particular data selection (see Sec.~\\ref{sec:data:dp1:preparation}),}\n\\item{\\textbf{flavor}: specifies a particular set of configuration parameters,}\n\\item{\\textbf{dataset}: specifies a particular dataset (see Sec.~\\ref{tab:dataset}).}\n\\item{\\textbf{version}: specifies a processing version (e.g., v1, v2).}\n\\end{itemize}\n\n\n\\subsection{Distribution via the Rubin Data Butler}\n\\label{sec:distribution:butler}\n\nCreation of photometric redshift estimates using RAIL in the Rubin DM framework and distribution via the Rubin Data Butler is supported the \\href{https://github.com/lsst-dm/meas_pz}{\\code{meas\\_pz}} software package for DM supported algorithms and by the \\href{https://github.com/lsst-dm/meas_pz}{\\code{meas\\_pz\\_extensions}} software package for the community-supported algorithms described in this note.\n\nFor DP1, the following objects stored in the data butler at USDF and NERSC are listed in Tab.~\\ref{tab:butler}.\n\n\\begin{table*}\n\\centering\n\\begin{tabular}{ll}\n \\hline\nDataset type & Description \\\\\n \\hline\n \\hline\n\\multicolumn{2}{l}{Collection: \\code{pretrained\\_models/pz/DP1/\\{selection\\}/\\{flavor\\}}} \\\\ \\hline\n\\code{pzModel\\_\\{algo\\}} & Estimator models (see ~\\ref{sec:products:models}) \\\\ \\hline\n\\multicolumn{2}{l}{Collection: \\code{LSSTComCam/runs/DRP/DP1/pz/DM-51523/\\{selection\\}/\\{flavor\\}/\\{version\\}}} \\\\  \\hline\n\\code{pz\\_estimate\\_\\{algo\\}} & QP ensembles (see ~\\ref{sec:products:qp_ensembles}) \\\\\n\\code{pz\\_\\{algo\\}\\_config} & Configuration parameters (see ~\\ref{sec:products:configuration}) \\\\\n\\code{pz\\_\\{algo\\}\\_log} & Log files \\\\\n\\code{pz\\_\\{algo\\}\\_metadata} & Processing metadata \\\\\n \\hline\n\\end{tabular}\n\\caption{Photo-z related objects stored in the Rubin Data Butler.  Note that \\code{\\{selection\\}} describes the selection applied to the trained data set.}\n\\label{tab:butler}\n\\end{table*}\n\n\n\\subsection{Distribution via the Photo-z Server}\n\\label{sec:distribution:linea}\n\n\nThe \\href{https://pzserver.linea.org.br/}{Photo-z Server (or PZ Server)} is a web-based service available for the LSST community to create and host PZ-related lightweight data products. It relies on the infrastructure of the Brazilian Independent Data Access Center and is developed and maintained by LIneA as part of the Brazilian in-kind contribution program.\n\nThe PZ server is open to any LSST member with a valid RSP account without the need for an extra local registry. Users can log into the system simply using the RSP credentials.\n\nAll data products described in this document\nwill be\nhosted on the PZ Server, along with their respective metadata and documentation. There are two ways to access these data products:\n\n\\subsubsection{From the PZ Server website}\n\nData products are listed both on the 'Rubin PZ Data Products' page (for official data products released or recommended by LSST DM) and 'User-generated data products' for data products produced or uploaded by the LSST community members. The DP1 PZ data products described in this document\nwill be\n\navailable in the first one.\n\n\n\n\n\n\n\n\n\\subsubsection{Via the \\code{pzserver} Python library}\n\nSimilar to the RSP, the PZ Server provides an API interface that enables users to access data through Python scripts from any location, provided they know the product name as registered on the server.\n\nIf it is the first time using the library, it must be installed via \\code{pip} in the terminal or in a notebook cell: \\code{pip install pzserver}\n\nThen, the \\code{PzServer} class opens the remote connection to the PZ Server database. An access token is required for authentication. The token can be generated by users on the PZ Server website (top right corner menu on the home page).\n\n\\begin{verbatim}\nfrom pzserver import PzServer\npz_server = PzServer(token=\"<paste your access token here>\")\n\\end{verbatim}\n\nTo display the product metadata and download it to the local working directory (if not in a Jupyter notebook, replace \\code{display} for \\code{get}):\n\\begin{verbatim}\npz_server.display_product_metadata(<product_id>)\npz_server.download_product(product_id, save_in=\".\")\n\\end{verbatim}\n\nAlternatively, it is possible to load a table directly into memory as a Pandas DataFrame or Astropy Table. For instance, to load a training set:\n\n\\begin{verbatim}\ntraining_set = pz_server.get_product(<training_set_id>)\ntraining_set.display_metadata()\n\\end{verbatim}\n\n\n\n\n\n\n\nA tutorial notebook with examples for all \\code{pzserver} methods is available on the \\href{https://github.com/linea-it/pzserver/blob/main/docs/notebooks/pzserver_tutorial.ipynb}{\\code{pzserver} library's repository on GitHub}.\n\n\n\\subsection{Distribution as files at USDF and NERSC}\n\\label{sec:distribution:files}\n\nAll of the test and training files, the outputs from runs used to optimize the model hyperparamters, as well as from the optimized models, the photo-z estimates for the entire DP1 dataset, are all available in \\code{rail\\_projects}-managed shared project area at both NERSC and USDF.  These data products are listed in Tab.~\\ref{tab:project_area}.\n\n\\begin{table*}\n\\centering\n\\begin{tabular}{ll}\n \\hline\nObject type  & Relative Path \\\\\n \\hline\n \\hline\nTraining data sets  & \\code{data/train/*.hdf5} \\\\\nTest data sets  & \\code{data/test/*.hdf5} \\\\ \\hline\n\\multicolumn{2}{l}{In : \\code{pz/projects/dp1/pipelines}} \\\\ \\hline\nPipeline configurations & \\code{\\{pipeline\\}\\_\\{flavor\\}.yaml} \\\\ \\hline\n\\multicolumn{2}{l}{In : \\code{pz/projects/dp1/data}} \\\\ \\hline\nEstimator models & \\code{\\{selection\\}\\_\\{flavor\\}/model\\_inform\\_\\{algo\\}.pkl} \\\\\nQP ensembles (for test data) & \\code{\\{selection\\}\\_\\{flavor\\}/output\\_estimate\\_\\{algo\\}.hdf5} \\\\\nQP ensembles (for other data) & \\code{\\{selection\\}\\_\\{flavor\\}/\\{dataset\\}/output\\_estimate\\_\\{algo\\}.hdf5} \\\\\n \\hline\n\\end{tabular}\n\\caption{Photo-z related files in the \\code{rail\\_projects}-managed shared project areas.}\n\\label{tab:project_area}\n\\end{table*}\n\n\n\\subsection{Distribution via LSDB}\n\\label{sec:distribution:lsdb}\n\nThe Large Survey DataBase (LSDB) will host the DP1 data on the USDF and the Canadian IDAC RSP. The DP1 data will be turned into Hierarchical Adaptive Tiling Scheme (HATS) format. LSDB enables researchers to load large datasets with limited memory, and fast cross match to other surveys like DESI DR1 and GAIA DR3.\n\nThe photo-z point estimates for DP1 in the \\textbf{#1}{ECDFS},\\textbf{#1}{EDFS}, \\textbf{#1}{Rubin\\_SV\\_95\\_-25}, and \\textbf{#1}{Rubin\\_SV\\_38\\_7}  will be served as a single tabular catalog in the LSDB. The location on the USDF for this catalog is \\texttt{/sdf/data/rubin/shared/lsdb\\_commissioning/dp1\\_pz\\_hats}.\n\n\n\\pagebreak\n\n\n\n\n\n\n\n\n\n\n\n\\section{References} \\label{sec:bib}\n\\renewcommand{\\refname}{}\n\\bibliography{local,lsst,lsst-dm,refs_ads,refs,books}\n\n\n\\section{Acronyms} \\label{sec:acronyms}\n\\addtocounter{table}{-1}\n\\begin{longtable}{p{0.145\\textwidth}p{0.8\\textwidth}}\\hline\n\\textbf{Acronym} & \\textbf{Description}  \\\\\\hline\n\n1D & One-dimensional \\\\\\hline\n3D & Three-dimensional \\\\\\hline\nAGN & Active Galactic Nuclei \\\\\\hline\nAPI & Application Programming Interface \\\\\\hline\nCDF & Cumulative Distribution Function \\\\\\hline\nCOSMOS & Cosmic Evolution Survey \\\\\\hline\nDESC & Dark Energy Science Collaboration \\\\\\hline\nDESI & Dark Energy Spectroscopic Instrument \\\\\\hline\nDM & Data Management \\\\\\hline\nDMTN & DM Technical Note \\\\\\hline\nDP1 & Data Preview 1 \\\\\\hline\nDP2 & Data Preview 2 \\\\\\hline\nDR1 & Data Release 1 \\\\\\hline\nDR3 & Data Release 3 \\\\\\hline\nDRP & Data Release Processing \\\\\\hline\nECDFS & Extended Chandra Deep Field-South Survey \\\\\\hline\nEDFS & Euclid Deep Field South \\\\\\hline\nELG & Emission-Line Galaxies \\\\\\hline\nGOODS & The Great Observatories Origins Deep Survey \\\\\\hline\nHST & Hubble Space Telescope \\\\\\hline\nIDAC & Independent Data Access Center \\\\\\hline\nJWST & James Webb Space Telescope (formerly known as NGST) \\\\\\hline\nLRG & Luminous Red Galaxies \\\\\\hline\nLSS & Large Scale Structure \\\\\\hline\nLSST & Legacy Survey of Space and Time (formerly Large Synoptic Survey Telescope) \\\\\\hline\nLSSTCam & LSST Science Camera \\\\\\hline\nLSSTComCam & Rubin Commissioning Camera \\\\\\hline\nMB & MegaByte \\\\\\hline\nNED & NASA/IPAC Extragalactic Database \\\\\\hline\nNERSC & National Energy Research Scientific Computing Center \\\\\\hline\nPDF & Portable Document Format \\\\\\hline\nPSTN & Project Science Technical Note \\\\\\hline\nPZ & photo-z \\\\\\hline\nRMS & Root-Mean-Square \\\\\\hline\nRSP & Rubin Science Platform \\\\\\hline\nRTN & Rubin Technical Note \\\\\\hline\nSE & System Engineering \\\\\\hline\nSED & Spectral Energy Distribution \\\\\\hline\nSNR & Signal to Noise Ratio \\\\\\hline\nSV & Science Validation \\\\\\hline\nUSDF & United States Data Facility \\\\\\hline\nYAML & Yet Another Markup Language \\\\\\hline\nphoto-z & photometric redshift \\\\\\hline\n\\end{longtable}\n\n\n\n\n\n\n\n\n\\end{document}\n\n\n\n\n",
  "author": [
    {
      "name": "Eric Charles",
      "@type": "Person"
    },
    {
      "name": "John Franklin Crenshaw",
      "@type": "Person"
    },
    {
      "name": "Tianqing Zhang",
      "@type": "Person"
    },
    {
      "name": "Sam Schmidt",
      "@type": "Person"
    },
    {
      "name": "Prakruth Adari",
      "@type": "Person"
    },
    {
      "name": "Johann Cohen-Tanugi",
      "@type": "Person"
    },
    {
      "name": "Melissa Graham",
      "@type": "Person"
    },
    {
      "name": "Julia Gschwend",
      "@type": "Person"
    },
    {
      "name": "Bryce Kalmbach",
      "@type": "Person"
    },
    {
      "name": "Arun Kannawadi",
      "@type": "Person"
    },
    {
      "name": "Alex Malz",
      "@type": "Person"
    },
    {
      "name": "Sidney Mau",
      "@type": "Person"
    },
    {
      "name": "Ignacio Sevilla-Noarbe",
      "@type": "Person"
    },
    {
      "name": "Rance Solomon",
      "@type": "Person"
    },
    {
      "name": "Dan Taranu",
      "@type": "Person"
    }
  ],
  "codeRepository": "https://github.com/lsst-sitcom/sitcomtn-154",
  "contIntegration": "https://github.com/lsst-sitcom/sitcomtn-154/actions/runs/16184835887",
  "dateModified": "2025-07-09T22:03:48Z",
  "description": "This technote holds reports based on the first analyses of the Data Preview 1 (DP1) data by the Science Unit for photometric redshifts. Although photometric redshifts are not a official DP1 data product, the \"Photo-z Science Unit\" generated photo-z estimates for every galaxy in DP1 using the available multi-band imaging on a best-effort basis. This work included developing training and test datasets by matching DP1 data to high-quality reference redshifts obtained with spectroscopy, Grism data, and multi-band photometry. The Science Unit used the RAIL software package to make photometric redshift estimates using eight different algorithms, developed simple scientific performance metrics, used those metrics to explore how the performance of the algorithms varied with configuration changes, derived more optimized configurations of the algorithms and tested the performance of those configurations. This work, the resulting data products and expected data distribution mechanism are all described there.\n",
  "fileFormat": "text/plain",
  "language": "TeX",
  "reportNumber": "SITCOMTN-154",
  "url": "https://sitcomtn-154.lsst.io"
}
